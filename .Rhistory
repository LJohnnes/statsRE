q1
# Answers
# histogram
q1 <- qplot(mpg$hwy, geom="blank") + geom_histogram(aes(x=hwy, y=..density..), colour=I("gray")) + stat_function(fun=dnorm, args=list(mean=xbar, sd=s), colour=I("red"))
q1
#qqplot
q2 <- qplot(data=mpg, sample=scale(hwy)) + stat_qq() + geom_abline(intercept=0, slope=1)
q2
grid.arrange(q1,q2,nrow=1)
q1 <- qplot(daya=mpg, hwy, geom="blank") + geom_histogram(aes(x=hwy, y=..density..), colour=I("gray")) + stat_function(fun=dnorm, args=list(mean=xbar, sd=s), colour=I("red"))
q1
library(mpg)
install.packages(mpg)
install.packages("mpg")
myModel <- lm(formula, data)
y ~ x1 + x2 + ... + xk
y ~ x1*x2 # with interaction, i.e., y = b0 + b1x1 + b2x2 + b3x1x2
myModel <- lm(formula, data)
library("women")
install.packages("women")
View(women)
# answer
qplot(data=women, height, weight, geom="point") + geom_smooth(method="lm", se=FALSE)
m1 = lm(data=women, weight ~ height)
summary(m1)
b1 = cor(women$height, women$weight)*sd(women$weight)/sd(women$height)
b1
b0 = mean(women$weight) - b1*mean(women$height)
print(b0)
anova(m1)
predict(m1)
predict(m1) #shows the value for each point, x vs y
qplot(data=women, weight, height, geom="point") + geom_smooth(method=lm, se=FALSE) + geom_segment(aes(x=women$height, y=women$weight, xend=women$height,yend=predict(m1)), colour=I("red"), alpha-I(0.5))
qplot(data=women, weight, height, geom="point") +
geom_smooth(method="lm", se=FALSE)+
geom_segment(aes(x=women$height, y=women$weight, xend=women$height,yend=predict(m1)), colour=I("red"), alpha-I(0.5))
qplot(data=women, weight, height, geom="point") +
geom_smooth(method="lm", se=FALSE) +
geom_segment(aes(x=women$height, y=women$weight, xend=women$height, yend=predict(m1)), colour=I("red"), alpha=I(0.5))
qplot(data=women, height, weight, geom="point") +
geom_smooth(method="lm", se=FALSE) +
geom_segment(aes(x=women$height, y=women$weight, xend=women$height, yend=predict(m1)), colour=I("red"), alpha=I(0.5))
(weight - predict(m1))^2
women %>%
(weight - predict(m1))^2
library(dplyr)
women %>%
(weight - predict(m1))^2
(women$weight - predict(m1))^2 %>% sum()
anova(m1)
ybar = mean(women$weight)
ybar
ybar = mean(women$weight)
qplot(women$weight, women$height, geom="point") +
geom_hline(aes(yintercept=ybar))
ybar = mean(women$weight)
qplot(women$height, women$weight, geom="point") +
geom_hline(aes(yintercept=ybar))
ybar = mean(women$weight)
qplot(women$height, women$weight, geom="point") +
geom_hline(aes(yintercept=ybar)) +
geom_segment(aes(x=women$height, y=women$weight, xend=women$height, yend=ybar), colour=I("red"), alpha=I(0.5))
SSE = (mean(women$weight) - women$weight)^2 %>% sum()
SSE
SStotal = (women$weight - ybar)^2 %>% sum()
SStotal
library(gridExtra)
grid.arrange(q1, q2, nrow=1)
qp1 <- qplot(data=women, height, weight, geom="point") +
geom_smooth(method="lm", se=FALSE) +
geom_segment(aes(x=women$height, y=women$weight, xend=women$height, yend=predict(m1)), colour=I("red"), alpha=I(0.5))
# may not want to minimize the square error
#answer
SSE = (women$weight - predict(m1))^2 %>% sum()
anova(m1)
# a very very simple regression would say "just take the average"
# can we calculate the error?
ybar = mean(women$weight)
qp2 <- qplot(women$height, women$weight, geom="point") +
geom_hline(aes(yintercept=ybar)) +
geom_segment(aes(x=women$height, y=women$weight, xend=women$height, yend=ybar), colour=I("red"), alpha=I(0.5))
# Sum of Squared total error = total variability of weight of people
SStotal = (mean(women$weight) - women$weight)^2 %>% sum()
# alt version
SStotal = (women$weight - ybar)^2 %>% sum()
#SSE = variability of something not in your regression model
#SStotal - SSE = SSB = variability in your regression model
library(gridExtra)
grid.arrange(qp1, qp2, nrow=1)
grid.arrange(qp2, qp1, nrow=1)
(SStotal - SSE)/SStotal
anova(m1)
summary(anova(m1))
summary(m1)
library(dplyr)
library(ggplot2)
library(dplyr)
library(hflights)
flights <- tbl_df(hflights)
flights #by default, it prints 10 rows
hflights
slice(flights, 1:3)
flights %>%
slice(1:3)
flights %>%
slice(1:10)
flights[flights$Month==1 & flights$DayofMonth==1, ]
flights %>%
filter(Month == 1 & DayofMonth == 1)
flights %>%
filter(Month == 2 & DayofMonth == 1)
flights[flights$Month==1, flights$DayofMonth==1, ] # pay attention to the ","
flights[flights$Month==1,flights$DayofMonth==1,]
flights %>%
filter(UniqueCarrier=='AA' & ArrDelay>30) %>%
n()
flights %>%
filter(UniqueCarrier=='AA' & ArrDelay>30) %>%
count()
flights %>%
filter(UniqueCarrier=="AA" & ArrDelay>30) %>%
count()
ff <-flights %>%
filter(UniqueCarrier=="AA" & ArrDelay>30)
count(ff)
b <- flights %>%
filter(UniqueCarrier=="AA" & ArrDelay > 30)
mean(b$ArrDelay)
flights %>%
filter(UniqueCarrier=="AA" & ArrDelay > 30) %>%
summarise(mean(ArrDelay))
flights %>%
filter(UniqueCarrier=="AA" & ArrDelay > 30) %>%
mean(ArrDelay)
flights %>%
filter(UniqueCarrier=="AA" & ArrDelay > 30) %>%
summarise(mean(ArrDelay))
flights %>%
filter(UniqueCarrier=="AA" & ArrDelay > 30) %>%
summarise(mean(ArrDelay))
a <- flights %>%
filter(UniqueCarrier == "AA") %>%
filter(ArrDelay > 30)
mean(a$ArrDelay)
flights %>%
filter(UniqueCarrier=="AA" & ArrDelay>30) %>%
summarise(n())
count(data=flights, filter(UniqueCarrier=="AA" & ArrDelay>30))
count(filter(flights$UniqueCarrier=="AA" & flights$ArrDelay>30))
flights %>%
filter(UniqueCarrier=="AA" & ArrDelay > 30) %>%
summarise(mean(ArrDelay))
a <- flights %>%
filter(UniqueCarrier == "AA") %>%
filter(ArrDelay > 30)
mean(a$ArrDelay)
flights[  , c("DepTime", "ArrTime", "FlightNum")]
flights %>%
filter(ArrDelay=max())
flights %>%
max(ArrDelay)
hflights %>%
max(ArrDelay)
flights %>%
filter(UniqueCarrier=='AA' & ArrDelay>30) %>%
summarise(n())
head(flights)
flights$ArrDelay %>%
summarise(max())
flights %>%
select(DepTime, ArrTime, FlightNum)
flights[  , c("DepTime", "ArrTime", "FlightNum")]
flights %>%
select(Year:DayofMonth, contains("Taxi"), contains("Delay"))
flights %>%
rename(Day_of_Month = DayofMonth)
head(flights)
flights <- flights %>%
rename(Day_of_Months = DayofMonth)
flights <- flights %>%
head(flights)
flights %>%
select(ArrDelay) %>%
max()
flights %>%
select(Origin) %>%
distinct()
dels <- flights %>%
select(ArrDelay > 0 & DepDelay > 0 )%>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)),ArrDelay, DepDelay)
dels <- flights %>%
select(ArrDelay>0 & DepDelay>0 )%>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)),ArrDelay, DepDelay)
dels <- flights %>%
select(ArrDelay>0 & DepDelay>0) %>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)),ArrDelay, DepDelay)
dels <- flights %>%
filter(ArrDelay>0 & DepDelay>0) %>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)),ArrDelay, DepDelay)
#take 1
dels
flights %>%
select(Origin) %>%
distinct()
delays <- flights %>%
select(Origin,ArrDelay,DepDelay) %>%
filter(ArrDelay>0 & DepDelay>0)
mean(delays$ArrDelay)
mean(delays$DepDelay)
median(delays$ArrDelay)
median(delays$DepDelay)
#take 1 plot
qplot(data=dels, x=(ArrDelay+DepDelay))
qplot(dels$ArrDelay)
plot(dels$ArrDelay)
histogram(dels$ArrDelay)
qplot(data=delays, ArrDelay+DepDelay, fill=factor(Origin), position="dodge", binwidth=200) + xlim(-200,1500)
qplot(data-dels, ArrDelay)
qplot(data=dels, ArrDelay)
dels <- flights %>%
filter(ArrDelay>0 & DepDelay>0) %>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)),ArrDelay, DepDelay)
dels
flights %>%
filter(ArrDelay>0 & DepDelay>0) %>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)),ArrDelay, DepDelay)
qplot(data=delays, ArrDelay+DepDelay, fill=factor(Origin), position="dodge", binwidth=200) + xlim(-200,1500)
#given solution
qplot(data=flights, ArrDelay)
qplot(data=flights, ArrDelay+DepDelay)
qplot(data=flights, ArrDelay+DepDelay, position="dodge")
qplot(data=delays, ArrDelay+DepDelay, fill=factor(Origin), position="dodge", binwidth=200) + xlim(-200,1500)
qplot(data=flights, ArrDelay+DepDelay, position="dodge")
delays <- flights %>%
select(Origin, ArrDelay, DepDelay) %>%
filter(ArrDelay > 0, DepDelay > 0)
mean(delays$ArrDelay)
mean(delays$DepDelay)
median(delays$ArrDelay)
median(delays$DepDelay)
qplot(data=delays, ArrDelay, colour=I("gray"))
qplot(data=delays, ArrDelay+DepDelay, fill=factor(Origin), position="dodge", binwidth=200) + xlim(-200,1500)
qplot(data=delays, ArrDelay, colour=I("gray"))
qplot(data=delays, ArrDelay + DepDelay, colour=I("gray"))
qplot(data=delays, ArrDelay+DepDelay, fill=factor(Origin), position="dodge", binwidth=200) + xlim(-200,1500)
qplot(data=delays, ArrDelay + DepDelay, colour=I("gray"), position="dodge")
delays <- flights %>%
filter(flights, ArrDelay>0 | DepDelay>0)
group_by(Origin) %>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)), ArrDelay, DepDelay)
delays <- flights %>%
filter(flights, ArrDelay>0 | DepDelay>0)
group_by(Origin) %>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)), ArrDelay, DepDelay)
dels <- flights %>%
filter(ArrDelay>0 | DepDelay>0) %>%
summarise_each(funs(mean(.,na.rm=TRUE), median(.,na.rm=TRUE)),ArrDelay, DepDelay)
dels
delays <- flights %>%
select(Origin,ArrDelay,DepDelay) %>%
filter(ArrDelay>0 & DepDelay>0)
mean(delays$ArrDelay)
mean(delays$DepDelay)
median(delays$ArrDelay)
median(delays$DepDelay)
delays <- flights %>%
select(Origin,ArrDelay,DepDelay) %>%
filter(ArrDelay>0 | DepDelay>0)
mean(delays$ArrDelay)
mean(delays$DepDelay)
median(delays$ArrDelay)
median(delays$DepDelay)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(car)
library(effects)
library(ggplot2)
library(dplyr)
library(GGally)
library(car)
data=read.csv("OnlineNewsPopularity.csv", stringsAsFactors = FALSE)
install.packages("igraph")
library(plotrix)
install.packages("plotrix")
library(igraph)
library(plotrix)
g <- erdos.renyi.game(n = 100, p.or.m = 0.05, directed = T, loops = F)
rr <- reciprocity(g)
g <- erdos.renyi.game(n = 100, p.or.m = 0.05, directed = T, loops = F)
plot(g)
dd<-degree(g)
dd<-degree(g)
bb <- betweenness.estimate(g)
bb <- betweenness(g)
cc <- closeness(g)
ll <- layout.fruchterman.reingold(g)
cols <- color.scale(dd, cs1=c(1,1), cs2=c(1,0), cs3=c(0,0))
cols
ll
cc
bb
rr
cols
size <--dd
g <- erdos.renyi.game(n = 100, p.or.m = 0.05, directed = T, loops = F)
plot(g)
# Compute reciprocity
rr <- reciprocity(g)
# Compute degree
dd<-degree(g)
# Betweenness and closeness
bb <- betweenness(g)
# in large graphs it's difficult to compute the betweenness
# better to compute it for a sample
cc <- closeness(g)
# there exist many layout options
ll <- layout.fruchterman.reingold(g)
# Colors
cols <- color.scale(dd, cs1=c(1,1), cs2=c(1,0), cs3=c(0,0))
# Size
size <--dd
plot(g, vertex.label="", edge.arrow.size=0.2, vertex.color=cols, vertex.size=dd)
plot(g, layout=ll, vertex.label="", edge.arrow.size=0.2, vertex.color=cols, vertex.size=dd)
cols <- rep("red", times = vcount(g))
plot(g, vertex.label="", edge.arrow.size=0.2, vertex.color=cols, vertex.size=dd)
cols[1:5] <- "blue"
plot(g, vertex.label="", edge.arrow.size=0.2, vertex.color=cols, vertex.size=dd)
cols[1:10] <- "blue"
plot(g, vertex.label="", edge.arrow.size=0.2, vertex.color=cols, vertex.size=dd)
cols[1:20] <- "blue"
plot(g, vertex.label="", edge.arrow.size=0.2, vertex.color=cols, vertex.size=dd)
install.packages("fUnitRoots")
library(fUnitRoots)
?arima.sim
?list
y <- arima.sim(n=200,list(order=c(2,1,0),ar=c(0.5,0.3)))
y
ts.plot(y)
par(mfrow=c(2,1))
acf(y)
pacf(y)
z<-diff(y) ts.plot(z) par(mfrow=c(2,1)) acf(z)
z<-diff(y)
z
z<-diff(y)
ts.plot(z)
ts.plot(z)
ts.plot(z)
par(mfrow=c(2,1))
acf(z)
pacf(z)
adfTest(y,lags=10,type=c("c"))
adfTest(z,lags=10,type=c("c"))
ts.plot(y)
acf(y)
pacf(y)
ts.plot(y)
acf(y)
pacf(y)
ts.plot(z)
ts.plot(z)
acf(z)
pacf(z)
y <- arima.sim(n=200,list(order=c(2,1,2),ar=c(0.5,0.3)))
y <- arima.sim(n=200,list(order=c(2,1,2),ar=c(0.5,0.3)))
y <- arima.sim(n=200,list(order=c(2,1,2),ar=c(0.5,0.3),ma=c(0.5,0.3)))
ts.plot(y)
ts.plot(y)
par(mfrow=c(2,1))
acf(y)
pacf(y)
z<-diff(y)
ts.plot(z)
par(mfrow=c(2,1))
acf(z)
pacf(z)
adfTest(y,lags=10,type=c("c"))
adfTest(z,lags=10,type=c("c"))
install.packages('ggmap')
install.packages("ggmap")
install.packages("ggmap")
install.packages("ggmap")
install.packages("ggmap")
require(ggmap)
require('ggmap')
require(ggmap)
install.packages("ggmap")
install.packages("ggmap")
plot(as.undirected(graph.tree(n=100,children=4)),vertex.size=2,vertex.label="")
igraph
library(igraph)
plot(as.undirected(graph.tree(n=100,children=4)),vertex.size=2,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=4)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=1)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=10)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=100)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=3)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=3)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=6)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=5)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=100,children=4)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=50,children=4)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=500,children=4)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.tree(n=20,children=4)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.star(n=20)),vertex.size=5,vertex.label="")
plot(as.undirected(graph.star(n=20)))
plot(as.undirected(graph.star(n=100)))
g = as.undirected(graph.tree(n=100,children=5))
g
plot(g)
g.edgelist
graph.edgelist(g)
graph.edgelist()
?graph.edgelist
?induced.subgraph
induced.subgraph(g)
induced.subgraph(g,impl=c("auto"))
?subgraph.edges
?clusters
clusters(g)
g
g = as.directed(graph.tree(n=100,children=5))
g
clusters(g)
shortest.paths(g)
?shortest.paths
setwd("~/Desktop/statmodelscode/statsRE")
library(dplyr)
library(ggplot2)
library(gridExtra)
library(stringi)
library(timeDate)
library(arules)
library(data.table)
data <- read.csv('DataMasters-3.csv', dec=",")
dim(data)
summary(data)
head(data)
tail(data)
#View(data)
cci <- read.csv('DP_LIVE_15032016091148702.csv', dec=",")
cci <- cci[which(cci$LOCATION == 'USA'),-c(1,2,3,4,5,8)]
data <- data[,-c(2,3,8)]
# Create new variables
data$age <- 2016 - data$Year.Built
data$relisted <- data$CDOM - data$ADOM
data$relisted[data$relisted>0] <- 1
#It was all because of using "/" instead of "-"
soldDates <- as.Date(data$Sold.Lease.Date, format = "%m-%d-%Y")
data$soldMonth <- format(as.Date(soldDates), "%m")
listDate <- soldDates-data$ADOM
data$listMonth <- format(as.Date(listDate), "%m")
data$soldDay <- weekdays(soldDates)
data$Unit.Number <- gsub('[^a-zA-Z0-9.]', '', data$Unit.Number)
data$floor <- stri_extract_first(data$Unit.Number, regex = "\\d")
data$floor <- as.numeric(data$floor)
#removing all sorts of characters (dollar signs in this case) and then changing as numeric
data$Sold.Lease.Price <- gsub('[^a-zA-Z0-9.]', '', data$Sold.Lease.Price)
data$List.Price <- gsub('[^a-zA-Z0-9.]', '', data$List.Price)
data$Price.Diff <- as.numeric(data$Sold.Lease.Price) - as.numeric(data$List.Price)
#Condo size as discrete
data$condoSize <- discretize(data$Sqft.Total, "cluster", categories = 3, labels=c("small", "medium", "large"))
View(data)
cci
soldDates
data$soldMonth
cci$TIME
class(cci$TIME)
data$Sold.Lease.Date
ccidate <- as.Date(cci$TIME, format = "%Y-%m")
ccidate
#ccidate <- as.Date(cci$TIME, format = "%Y-%m")
cci$TIME
class(cci$TIME)
head(data)
names(data)
data <- data[,-c(1,2,3,8)]
# Create new variables
data$age <- 2016 - data$Year.Built
data$relisted <- data$CDOM - data$ADOM
data$relisted[data$relisted>0] <- 1
#It was all because of using "/" instead of "-"
soldDates <- as.Date(data$Sold.Lease.Date, format = "%m-%d-%Y")
data$soldMonth <- format(as.Date(soldDates), "%m")
listDate <- soldDates-data$ADOM
data$listMonth <- format(as.Date(listDate), "%m")
data$soldDay <- weekdays(soldDates)
data$Unit.Number <- gsub('[^a-zA-Z0-9.]', '', data$Unit.Number)
data$floor <- stri_extract_first(data$Unit.Number, regex = "\\d")
data$floor <- as.numeric(data$floor)
#removing all sorts of characters (dollar signs in this case) and then changing as numeric
data$Sold.Lease.Price <- gsub('[^a-zA-Z0-9.]', '', data$Sold.Lease.Price)
data$List.Price <- gsub('[^a-zA-Z0-9.]', '', data$List.Price)
data$Price.Diff <- as.numeric(data$Sold.Lease.Price) - as.numeric(data$List.Price)
#Condo size as discrete
data$condoSize <- discretize(data$Sqft.Total, "cluster", categories = 3, labels=c("small", "medium", "large"))
soldDates <- as.Date(data$Sold.Lease.Date, format = "%m-%d-%Y")
data$soldMonth <- format(as.Date(soldDates), "%m")
dim(data)
names(data)
ggpairs(data)
library(gridExtra)
ggpairs(data)
library(GGally)
ggpairs(data)
ggpairs(data)
names(data)
lm(data, Sold.Lease.Price ~ condoSize)
ggpairs(data[,c(10,14,16,18,25)])
ggpairs(data[,c(10,14,16,18,25)])
cor(data[,c(10,14,16,18,25)])
